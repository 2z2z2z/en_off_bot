# Комплексный план рефакторинга

## 1. Диагностика текущей архитектуры

### 1.1 Точка входа (`index.js`)

- **3184 строки**, объединяющих bootstrap, DI, роутинг событий, бизнес-логику, админ-панель и утилиты; многократные прямые `require`/`process.env` обращения усложняют композицию и тестирование.
- Глобальные структуры (`userStates`, `messageUpdateThrottle`, таймеры накопления) живут рядом с обработкой команд, что мешает переиспользованию и проявляет гонки при подключении новых платформ.
- Потоки ввода-вывода Telegram/VK размазаны по файлу (обработчики команд, callback'ов, текстов) и используют условные конструкции вместо декларативной маршрутизации.
- Админ-панель и whitelist обрабатываются на том же слое, что и gameplay: сложно отключить или переиспользовать, отсутствует разграничение доступа и логическое закапсулирование.

### 1.2 Домен ответов и очередей (`src/core/answer-service.js`)

- Файл на **724 строки** содержит сразу четыре подсистемы: отправка одиночных ответов, офлайн-очередь, буфер накопления, завершение пачек. Логика ветвится по платформам и уровневым сценариям, что увеличивает вероятность регрессий при добавлении новых каналов.
- **КРИТИЧНО:** Метод `sendAnswerToEncounter` занимает **259 строк (строки 78-336)** — это антипаттерн, требующий приоритетной декомпозиции. Он содержит проверку pendingDecisions, обнаружение смены уровня, retry-логику, обновление cookies и форматирование прогресс-сообщений.
- Сервис жёстко зависит от Messenger API и от структуры пользователя из `user-store`; отсутствует явный контракт (интерфейс) для интеграции, сложнее покрывать тестами.
- Много побочных эффектов (обновление `user.pending…`, вызовы `saveUserData()`, форматирование сообщений) внутри одного метода — затрудняет оптимизацию/кэширование и даунтайм-обработку.

### 1.3 Encounter API (`encounter-api.js`)

- **817 строк** с пересечением задач: сетевой транспорт, rate limiting, кэш уровней, интерпретация ответов, повторная авторизация и журналирование.
- Логика повторных запросов дублируется в `sendAnswer()` и `getGameState()`, сложнее поддерживать.
- Нет централизованной типизации ошибок (используются флаги, текстовые сравнения), что создаёт хрупкие места в вызывающих сервисах.

### 1.4 Работа с данными (`src/core/user-store.js`, `user_data.json`)

- **Production масштаб:** В реальной эксплуатации проект обслуживает **100-500+ пользователей**, каждый из которых может играть в разные игры на протяжении года и дольше.
- **Рост данных:** При среднем размере профиля 3-5KB на пользователя, включая очереди (`pendingAnswers`), буферы (`accumulatedAnswers`), временные метки (`recentMessageTimestamps`) и cookies, размер `user_data.json` в production составит:
  - **Базовые профили:** 500 пользователей × 3KB = 1.5MB
  - **Очереди при офлайне:** +2-5MB (50-100 кодов на активного пользователя)
  - **История timestamps:** +0.5-1MB за год
  - **Буферы накопления:** +1-2MB при активной игре
  - **ИТОГО:** 5-10MB реально, до 50MB возможно
- **Критические проблемы JSON на этом масштабе:**
  - **Загрузка в память:** Весь файл (10MB) загружается целиком при каждом чтении, независимо от того, нужен один пользователь или все.
  - **Полная перезапись:** Каждый вызов `saveUserData()` перезаписывает весь файл на диск, что при 10MB и частых операциях создаёт значительную нагрузку на I/O.
  - **Отсутствие транзакций:** Крэш во время записи приведёт к потере или повреждению всех данных; нет атомарности операций.
  - **Race conditions:** Concurrent запись от Telegram и VK адаптеров может привести к конфликтам и потере обновлений.
  - **Нет индексации:** Поиск пользователя по userId/gameId требует O(n) перебора всего массива.
  - **Нет query возможностей:** Невозможно выполнить запросы типа "все пользователи игры X" или "пользователи с непустыми очередями" без загрузки всех данных.
  - **Отсутствие TTL:** Старые временные данные (timestamps, завершённые очереди) накапливаются бесконечно без автоматической очистки.
  - **Backup сложен:** Копирование 10MB файла во время активной записи рискованно и может захватить частично обновлённое состояние.
- Хранилище смешивает долгоживущие данные (login, password, domain) и runtime состояние (таймеры, очереди, буферы) в единой структуре без разделения жизненного цикла.
- Нет явного слоя валидации/миграций поверх пользовательских данных, что критично при смене формата или добавлении новых полей.

### 1.5 Платформенные адаптеры (`src/platforms/*`)

- **Текущая реализация:** Адаптеры Telegram/VK реализованы **на высоком уровне** через базовый класс `PlatformAdapter` (130 строк), который УЖЕ обеспечивает:
  - Единый протокол событий через `PlatformEventType` (COMMAND, CALLBACK, TEXT)
  - Нормализацию userId через `normalizeUserId()`
  - Стандартизированный `emitEvent()` и `_normalizeEvent()`
  - Регистрацию в `messenger.js` через единый transport registry
- **Что требует улучшения:** Несмотря на хорошую архитектуру адаптеров, в бизнес-логике (`index.js`) остаются платформенно-зависимые участки:
  - Форматирование сообщений (HTML для Telegram vs plain text для VK) разбросано по коду
  - Генерация inline-клавиатур содержит условия `if (platform === 'telegram')` / `else if (platform === 'vk')`
  - UI-компоненты (кнопки, меню) создаются ad-hoc без единой фабрики
- Добавление третьей платформы потребует минимальных правок благодаря существующей архитектуре, но форматирование и клавиатуры нуждаются в выносе в отдельный presentation-слой.

### 1.6 Конфигурация, инфраструктура и наблюдаемость

- `console.log`/`console.error` разбросаны и не структурированы; отсутствует единый логгер с уровнями, нет разделения журналов по компонентам.
- Нет абстракции над конфигами: прямое чтение `.env`, `admin_config.json` и `process.env` делает невозможным тестирование без настоящего файла.
- Инструментов для регрессии (smoke/интеграционные тесты, мок Encounter) нет, что усложняет проверки во время рефакторинга.

## 2. Целевое видение архитектуры

1. **Слой приложений**: компактный bootstrap, который собирает платформы, сервисы и обработчики через конфигурацию.
2. **Доменные сервисы**: модули для ответов, очередей, накопления, whitelist, админки с чёткими интерфейсами и минимумом побочных эффектов.
3. **Инфраструктурные адаптеры**: Encounter-клиент, хранилище данных, логирование, платформы — каждый изолирован и заменяем.
4. **Расширяемость**: добавление платформы/фичи требует подключения нового адаптера и регистраций, а не правок по всему приложению.
5. **Наблюдаемость и тестируемость**: модульные тесты для доменных сервисов, упрощённые сценарии ручного тестирования, структурированные логи.

## 3. Предлагаемые изменения

### 3.1 Декомпозиция точки входа

- Вынести bootstrap в `src/app/bootstrap.js`: загрузка env, admin-конфига, user-store, запуск платформ и graceful shutdown.
- Создать `src/app/bot-engine.js`, который принимает список зарегистрированных платформ и мапу обработчиков событий (`command`, `callback`, `text`), избавив `index.js` от условных конструкций.
- Разнести обработчики по директориям `src/flows/setup`, `src/flows/main-menu`, `src/flows/admin`: каждый экспортирует функции, работающие через общий контекст (userStore, messageBus, answerService).
- Сконфигурировать DI-слой (простую «контейнер»-функцию или фабрику) для прокидывания зависимостей и упрощения тестов.

### 3.2 Сервисный слой ответов и потоков

- Разделить `answer-service` на модули:
  - `answer-delivery` — отправка одиночных ответов и защита от смены уровня.
  - `queue-processor` — офлайн-очередь с отдельным состоянием и стратегией повторов.
  - `burst-detector` и `batch-buffer` — детект всплесков + управление накоплением.
- Описать контракты (JSDoc/TypeScript d.ts) между сервисами и потребителями (сервер бота, userStore), чтобы новые платформы могли переиспользовать те же API.
- Перенести форматирование пользовательских сообщений в dedicated `presentation` модуль, уменьшая количество UI-веток в доменном коде.

### 3.3 Управление данными пользователей

**Обоснование SQLite:**

- Учитывая production масштаб (100-500+ пользователей) и критические проблемы JSON (см. раздел 1.4), переход на SQLite является **критически необходимым**, а не опциональным улучшением.
- SQLite обеспечивает транзакционность, индексацию, query возможности, TTL-очистку и инкрементальные backups при минимальных требованиях к инфраструктуре (нет необходимости в отдельном сервере БД).

**Схема базы данных:**

```sql
-- Долгоживущие профили пользователей
CREATE TABLE profiles (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  user_id TEXT NOT NULL UNIQUE,        -- userId от платформы (telegram:123, vk:456)
  platform TEXT NOT NULL,               -- telegram, vk
  login TEXT,                           -- логин на Encounter
  encrypted_password TEXT,              -- зашифрованный пароль
  domain TEXT,                          -- домен игры (world.en.cx и т.д.)
  created_at INTEGER NOT NULL,          -- timestamp создания
  updated_at INTEGER NOT NULL,          -- timestamp последнего обновления
  INDEX idx_user_platform (user_id, platform)
);

-- Активные игровые сессии
CREATE TABLE game_sessions (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  profile_id INTEGER NOT NULL,
  game_id TEXT NOT NULL,                -- gameId на Encounter
  auth_cookies TEXT,                    -- сериализованные cookies
  last_level_id TEXT,                   -- ID последнего уровня для кеша
  last_sync INTEGER NOT NULL,           -- timestamp последней синхронизации
  FOREIGN KEY (profile_id) REFERENCES profiles(id) ON DELETE CASCADE,
  INDEX idx_game_id (game_id),
  INDEX idx_profile_session (profile_id, game_id)
);

-- Runtime состояние (очереди, буферы, временные данные)
CREATE TABLE runtime_state (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  profile_id INTEGER NOT NULL,
  pending_answers TEXT,                 -- JSON-массив очереди ответов
  accumulated_answers TEXT,             -- JSON-массив накопленных кодов
  recent_timestamps TEXT,               -- JSON-массив timestamp'ов для throttling
  is_processing_queue BOOLEAN DEFAULT 0,
  is_accumulating BOOLEAN DEFAULT 0,
  accumulation_timer_end INTEGER,       -- timestamp завершения накопления
  created_at INTEGER NOT NULL,
  updated_at INTEGER NOT NULL,
  FOREIGN KEY (profile_id) REFERENCES profiles(id) ON DELETE CASCADE,
  UNIQUE(profile_id)
);
```

**Ключевые возможности SQLite решения:**

1. **Транзакции:** Атомарность операций предотвращает потерю данных при крэшах
2. **Индексы:** Быстрый поиск по userId, gameId, platform (O(log n) вместо O(n))
3. **Query возможности:** Запросы типа "все пользователи игры X", "пользователи с непустыми очередями", аналитика
4. **Нормализация:** Разделение profiles/sessions/runtime устраняет дублирование
5. **Foreign Keys:** Cascade delete автоматически очищает связанные данные
6. **Connection pooling:** Параллельные запросы от разных платформ без race conditions
7. **Incremental backup:** Возможность бэкапа без остановки приложения

**Слой репозитория:**

- Реализовать класс `UserRepository` с методами:
  - `getProfile(userId, platform)` — получение профиля
  - `saveProfile(profile)` — сохранение/обновление профиля
  - `getGameSession(profileId, gameId)` — получение игровой сессии
  - `updateAuthCookies(sessionId, cookies)` — обновление cookies
  - `getRuntimeState(profileId)` — получение runtime состояния
  - `updateRuntimeState(profileId, state)` — обновление очередей/буферов
  - `cleanupOldTimestamps(maxAge)` — очистка старых temporary данных
- Репозиторий скрывает детали хранения и обеспечивает единый интерфейс для сервисов

**TTL и автоматическая очистка:**

- Добавить фоновую задачу (setInterval каждые 6-12 часов):
  - Удаление timestamp'ов старше 24 часов из `recent_timestamps`
  - Очистка завершённых накоплений (где `accumulation_timer_end` истёк)
  - Удаление неактивных runtime_state (без обновлений >30 дней)
- Ограничение размеров буферов на уровне репозитория (max 100 элементов в `pending_answers`)

**План миграции:**

1. **Параллельный режим:** Реализовать репозиторий, который пишет в оба хранилища (JSON + SQLite)
2. **Миграция данных:** Скрипт `migrate-json-to-sqlite.js` для переноса существующих `user_data.json`
3. **Тестирование:** Проверка на production-подобном датасете (100+ пользователей)
4. **Постепенный переход:** Включить чтение из SQLite, затем отключить запись в JSON
5. **Финализация:** Отключить JSON полностью, сохранить как архив
6. **Rollback план:** Возможность вернуться к JSON через export из SQLite

**Валидация и миграции:**

- Версионирование схемы БД (таблица `schema_version`)
- При старте приложения проверять версию и применять миграции
- Валидация структуры данных перед сохранением (проверка обязательных полей, типов, лимитов)

### 3.4 Перестройка Encounter API

- **Текущее состояние:** Класс EncounterAPI (817 строк) уже имеет хорошо реализованные компоненты:
  - Queue-based rate limiter работает корректно
  - Кеш уровней с per-user ключами функционирует правильно
  - AuthCallback с мьютексом предотвращает гонки при реавторизации
- **Приоритетные улучшения:**
  - **Кастомные классы ошибок:** Создать иерархию ошибок (`EncounterError`, `LevelChangedError`, `AuthRequiredError`, `NetworkError`) вместо текстовых сравнений. Это упростит обработку ошибок в answer-service и других потребителях.
  - **Структурированный логгер:** Заменить console.log/error на структурированное логирование (pino) с уровнями (debug, info, warn, error) и контекстом запросов.
- **Не требуется:** Избыточная декомпозиция на множество мелких классов (EncounterTransport, SessionManager, LevelCache) снизит читаемость без реальной пользы. Текущая структура класса адекватна размеру и функциональности.

### 3.5 Платформенные адаптеры и событийная шина

- **Текущее состояние:** Архитектура адаптеров УЖЕ реализована на **80-90%**:
  - `PlatformAdapter` базовый класс определяет единый протокол (`PlatformEventType`, нормализация событий)
  - `messenger.js` предоставляет transport registry для всех платформ
  - index.js выполняет роль центрального router'а через `handleCommand()`, `handleCallback()`, `handleTextMessage()`
- **Минимальные улучшения:**
  - **Фабрика клавиатур:** Создать `src/presentation/keyboard-factory.js` с методами:
    - `createInlineKeyboard(buttons, platform)` — генерация inline-клавиатур для telegram/vk
    - `createReplyKeyboard(buttons, platform)` — генерация reply-клавиатур
    - Устраняет разбросанные `if (platform === 'telegram')` при создании UI
  - **Presentation-слой форматирования:** Вынести форматирование сообщений в `src/presentation/message-formatter.js`:
    - `formatLevelInfo(levelData, platform)` — HTML для Telegram, plain text для VK
    - `formatProgress(progress, platform)` — форматирование прогресса
    - Убирает платформенно-зависимый код из бизнес-логики
- **Не требуется:**
  - Переписывание существующих адаптеров (они работают хорошо)
  - "Шаблоны для новых платформ" (Discord/web не планируются, избыточно по YAGNI)

### 3.6 Админка и whitelist

- Вынести whitelist в сервис (`src/services/whitelist-service.js`) с отдельным репозиторием, добавив поддержку нескольких ролей и валидацию входных данных.
- Админ-панель реализовать как независимый flow с авторизацией и собственным состоянием, использовать markdown-разметку генерации через адаптер.

### 3.7 Инфраструктура и качество

- Ввести модуль логирования (например, `pino`) с поддержкой уровней, контекста пользователя и корреляции событий.
- Создать пакет вспомогательных тестов: mock Encounter (nock), сценарии for flows (Jest). Минимум — тесты для `parseGameUrl`, `burst-detector`, `queue-processor`.
- Добавить `npm run lint` (ESLint + Prettier) и форматирование, что сократит «шум» в будущем.
- Обновить документацию (`docs/platforms.md`, `docs/testing.md`) с новой архитектурой и контрольными сценариями.

## 4. Роадмап реализации

1. **Фаза 0 — подготовка**: договориться по целевой структуре директорий, ввести логгер и покрыть существующие вспомогательные функции тестами (заранее фиксируем поведение).
2. **Фаза 1 — инфраструктура**: вынести bootstrap, организовать DI/контейнер, перевести `index.js` на новые модули без изменения поведения.
3. **Фаза 2 — доменные сервисы**: поочередно выделить `answer-delivery`, `queue-processor`, `burst-detector`, адаптировать call-sites.
4. **Фаза 3 — хранилище и админка**: внедрить новый userStore, мигрировать whitelist, обновить документацию и скрипты резервного копирования.
5. **Фаза 4 — Encounter API и платформы**: рефакторинг клиента, унификация адаптеров, подготовка шаблонов для будущих платформ.
6. **Фаза 5 — QA и релиз**: обкатка по чеклисту (`docs/testing.md`), регрессия на обеих платформах, обновление Docker/PM2 инструкций.

План рассчитан на итеративный подход: каждая фаза завершается стабильной версией, регрессию можно проводить по чеклисту, а изменения изолированы по модулям.
